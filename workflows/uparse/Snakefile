import pandas as pd
import os
import textwrap

configfile: "config.json"
localrules: all, mkdir

df = pd.read_csv(config["meta_file"], sep='\t', header=0, index_col=0)
sample_ids = list(df.index)
df.index = sample_ids

def get_pair_gz(sample_id):
    dir = config["raw_fastq_gz_dir"]
    return tuple(os.path.join(dir, df.loc[str(sample_id), x]) for x in ('ForwardFastqGZ', 'ReverseFastqGZ'))

def get_primer_len(sample_id):
    return tuple(str(len(df.loc[str(sample_id), x])) for x in ('ForwardPrimer', 'ReversePrimer'))

rule all:
    input: 
        expand("{dir}/{file}", dir=config["dir_names"]["table_dir"], file=config["file_names"]["table_results"]["absolute_otu_table"]),
        expand("{dir}/{file}", dir=config["dir_names"]["table_dir"], file=config["file_names"]["table_results"]["seq_count_table"])

rule mkdir:
    output: touch(config["file_names"]["mkdir_done"])
    params: dirs = config["dir_names"].values()
    shell: "mkdir -p {params.dirs}"

rule unzip:
    input: 
        lambda wildcards: get_pair_gz(wildcards.sample_id),
        rules.mkdir.output
    output:
        config["dir_names"]["unzip_dir"] + "/{sample_id}_R1.fq",
        config["dir_names"]["unzip_dir"] + "/{sample_id}_R2.fq"
    shell:
        "gunzip -c {input[0]} > {output[0]} && gunzip -c {input[1]} > {output[1]}"

rule join:
    input: rules.unzip.output
    output: config["dir_names"]["join_dir"] + "/{sample_id}.assembled.fastq"
    version: config["tool_version"]["pear"]
    shell: "tools/pear/{version}/pear -f {input[0]} -r {input[1]} -o join/{wildcards.sample_id}"

rule filter:
    input: rules.join.output
    output: config["dir_names"]["filter_dir"] + "/{sample_id}.fq"
    version: config["tool_version"]["fastx"]
    params:
        percentage = config["parameters"]["quality_filtering"]["percentage"],
        qscore = config["parameters"]["quality_filtering"]["qscore"]
    shell: "tools/fastx/{version}/fastq_quality_filter -i {input} -o {output} -q {params.qscore} -p {params.percentage} -Q33 -v"

rule fq_2_fa:
    input: rules.filter.output
    output: config["dir_names"]["fq_2_fa_dir"] + "/{sample_id}.fa"
    version: config["tool_version"]["fastx"]
    #shell: "tools/fastx/{version}/fastq_to_fasta -i {input} -o {output} -n -r -v -Q33"
    shell: "tools/fastx/{version}/fastq_to_fasta -i {input} -o {output} -n -v -Q33"

rule strip:
    input: rules.fq_2_fa.output
    output: config["dir_names"]["strip_dir"] + "/{sample_id}.fa"
    params: plen=lambda wildcards: get_primer_len(wildcards.sample_id)
    shell: "python tools/my-tools/primer_striper.py {input} {output} {params.plen[0]} {params.plen[1]}"

rule concat:
    input: expand("{dir}/{sample_id}.fa", dir=config["dir_names"]["strip_dir"], sample_id=sample_ids)
    output: config["dir_names"]["uparse_dir"] + "/reads.fa"
    shell: "python tools/my-tools/concat_stripped.py {input} {output}"

rule uparse:
    input: 
        reads = rules.concat.output,
        chimera_db = expand("{dir}/{name}/{version}/{file}", dir=config["chimera_db"]["base_dir"], name=config["chimera_db"]["name"], version=config["chimera_db"]["version"], file=config["chimera_db"]["fa_file"])
    output: 
        rep_fa = config["dir_names"]["uparse_dir"] + "/otus.fa",
        table = config["dir_names"]["uparse_dir"] + "/otu_table.txt"
    version: config["tool_version"]["uparse"]
    params:
        uparse_dir = config["dir_names"]["uparse_dir"]
    shell: textwrap.dedent('''\
        tools/uparse/{version}/usearch -derep_fulllength {params.uparse_dir}/reads.fa -fastaout {params.uparse_dir}/derep.fa -sizeout
        tools/uparse/{version}/usearch -sortbysize {params.uparse_dir}/derep.fa -fastaout {params.uparse_dir}/sorted.fa -minsize 2
        tools/uparse/{version}/usearch -cluster_otus {params.uparse_dir}/sorted.fa -otus {params.uparse_dir}/otus1.fa -relabel OTU_ -sizeout -uparseout {params.uparse_dir}/results.txt
        tools/uparse/{version}/usearch -uchime_ref {params.uparse_dir}/otus1.fa -db {input.chimera_db} -strand plus -nonchimeras {output.rep_fa}
        tools/uparse/{version}/usearch -usearch_global {params.uparse_dir}/reads.fa -db {output.rep_fa} -strand plus -id 0.97 -uc {params.uparse_dir}/map.uc
        python2 tools/uparse_py/uc2otutab.py {params.uparse_dir}/map.uc > {params.uparse_dir}/otu_table.txt''').replace("\n", " && ")

rule mkblastdb:
    input: expand("{dir}/{name}/{version}/{file}", dir=config["annotation_db"]["base_dir"], name=config["annotation_db"]["name"], version=config["annotation_db"]["version"], file=config["annotation_db"]["fa_file"])
    output: touch(config["file_names"]["mkblastdb_done"])
    version: config["tool_version"]["blast+"]
    params: db_name = config["annotation_db"]["name"]
    shell: "tools/blast+/{version}/bin/makeblastdb -in {input} -out {params.db_name} -dbtype 'nucl' -input_type fasta"

rule blast:
    input: 
        query = rules.uparse.output.rep_fa,
        mkblastdb_done = rules.mkblastdb.output 
    output: config["dir_names"]["uparse_dir"] + "/annotation.txt"
    version: config["tool_version"]["blast+"]
    params:
        identity = config["parameters"]["blast"]["identity"],
        coverage = config["parameters"]["blast"]["coverage"],
        num_threads = config["parameters"]["blast"]["num_threads"],
        db_name = config["annotation_db"]["name"]
    shell: 'tools/blast+/{version}/bin/blastn -query {input.query} -task megablast -db {params.db_name} -perc_identity {params.identity} -qcov_hsp_perc {params.coverage} -evalue 1e-6 -max_target_seqs 5 -outfmt "7 qacc sacc qstart qend sstart send length pident qcovhsp qcovs" -out {output} -num_threads {params.num_threads}'
    
rule make_otu_table:
    input: 
        taxonomy = expand("{dir}/{name}/{version}/{file}", dir=config["annotation_db"]["base_dir"], name=config["annotation_db"]["name"], version=config["annotation_db"]["version"], file=config["annotation_db"]["tax_file"]),
        table = rules.uparse.output.table,
        annotation = rules.blast.output
    output: expand("{dir}/{file}", dir=config["dir_names"]["table_dir"], file=config["file_names"]["table_results"]["absolute_otu_table"])
    shell: "python build_otu_table.py {input.taxonomy} {input.annotation} {input.table} {output}"

rule count:
    input:
        original_count = expand("{dir}/{sample_id}_R1.fq", dir=config["dir_names"]["unzip_dir"], sample_id=sample_ids),
        join_count = expand("{dir}/{sample_id}.assembled.fastq", dir=config["dir_names"]["join_dir"], sample_id=sample_ids),
        filter_count = expand("{dir}/{sample_id}.fq", dir=config["dir_names"]["filter_dir"], sample_id=sample_ids),
        blast_count = rules.make_otu_table.output
    output: expand("{dir}/{file}", dir=config["dir_names"]["table_dir"], file=config["file_names"]["table_results"]["seq_count_table"])
    shell: "python count.py {input.original_count} {input.join_count} {input.filter_count} {input.blast_count} {output}"
    
rule clean:
    params: 
        dirs = config["dir_names"].values(),
        database = config["annotation_db"]["name"] + "*",
        mkdir_done = config["file_names"]["mkdir_done"],
        mkblastdb_done = config["file_names"]["mkblastdb_done"]
    shell: "rm -rf {params.dirs} {params.mkdir_done} {params.database} {params.mkblastdb_done}"

rule unlink:
    shell: "find . -maxdepth 1 -type l -exec rm {{}} \;"
