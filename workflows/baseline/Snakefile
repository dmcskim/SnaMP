import pandas as pd
import os

configfile: "config.json"

df = pd.read_csv(config["meta_file"], sep='\t', header=0)
sample_ids = list(df['#SampleID'])
df.index = sample_ids

def get_pair_gz(sample_id):
    dir = config["raw_fastq_gz_dir"]
    return tuple(os.path.join(dir, df.loc[str(sample_id), x]) for x in ('ForwardFastqGZ', 'ReverseFastqGZ'))

def get_primer_len(sample_id):
    return tuple(str(len(df.loc[str(sample_id), x])) for x in ('ForwardPrimer', 'ReversePrimer'))

rule all:
    input: 
        expand("{dir}/{file}", dir=config["dir_names"]["table_dir"], file=config["file_names"]["table_results"]["relative_otu_table"]),
        expand("{dir}/{file}", dir=config["dir_names"]["table_dir"], file=config["file_names"]["table_results"]["absolute_otu_table"]),
        expand("{dir}/{file}", dir=config["dir_names"]["table_dir"], file=config["file_names"]["table_results"]["seq_count_table"])

rule mkdir:
    output: touch(config["file_names"]["mkdir_done"])
    params: dirs = config["dir_names"].values()
    shell: "mkdir -p {params.dirs}"

rule unzip:
    input: 
        lambda wildcards: get_pair_gz(wildcards.sample_id),
        rules.mkdir.output
    output:
        config["dir_names"]["unzip_dir"] + "/{sample_id}_R1.fq",
        config["dir_names"]["unzip_dir"] + "/{sample_id}_R2.fq"
    shell:
        "gunzip -c {input[0]} > {output[0]} && gunzip -c {input[1]} > {output[1]}"

rule join:
    input: rules.unzip.output
    output: config["dir_names"]["join_dir"] + "/{sample_id}.assembled.fastq"
    version: config["tool_version"]["pear"]
    shell: "tools/pear/{version}/pear -f {input[0]} -r {input[1]} -o join/{wildcards.sample_id}"

rule filter:
    input: rules.join.output
    output: config["dir_names"]["filter_dir"] + "/{sample_id}.fq"
    version: config["tool_version"]["fastx"]
    params:
        percentage = config["parameters"]["quality_filtering"]["percentage"],
        qscore = config["parameters"]["quality_filtering"]["qscore"]
    shell: "tools/fastx/{version}/fastq_quality_filter -i {input} -o {output} -q {params.qscore} -p {params.percentage} -Q33 -v"

rule fq_2_fa:
    input: rules.filter.output
    output: config["dir_names"]["fq_2_fa_dir"] + "/{sample_id}.fa"
    version: config["tool_version"]["fastx"]
    shell: "tools/fastx/{version}/fastq_to_fasta -i {input} -o {output} -n -r -v -Q33"

rule strip:
    input: rules.fq_2_fa.output
    output: config["dir_names"]["strip_dir"] + "/{sample_id}.fa"
    params: lambda wildcards: get_primer_len(wildcards.sample_id)
    shell: "python tools/my-tools/primer_striper.py {input} {output} {params[0]} {params[1]}"

rule collapse:
    input: rules.strip.output
    output: config["dir_names"]["collapse_dir"] + "/{sample_id}.fa"
    version: config["tool_version"]["fastx"]
    shell: "tools/fastx/{version}/fastx_collapser -i {input} -o {output} -v"

rule mkblastdb:
    input: expand("{dir}/{name}/{version}/{file}", dir=config["database"]["base_dir"], name=config["database"]["name"], version=config["database"]["version"], file=config["database"]["fa_file"]) 
    output: touch(config["file_names"]["mkblastdb_done"])
    version: config["tool_version"]["blast+"]
    params: db_name = config["database"]["name"]
    shell: "tools/blast+/{version}/bin/makeblastdb -in {input} -out {params.db_name} -dbtype 'nucl' -input_type fasta"

rule blast:
    input: 
        query = rules.collapse.output,
        mkblastdb_done = rules.mkblastdb.output 
    output: config["dir_names"]["blast_dir"] + "/{sample_id}.txt"
    version: config["tool_version"]["blast+"]
    params:
        identity = config["parameters"]["blast"]["identity"],
        coverage = config["parameters"]["blast"]["coverage"],
        db_name = config["database"]["name"]
    shell: 'tools/blast+/{version}/bin/blastn -query {input.query} -task megablast -db {params.db_name} -perc_identity {params.identity} -qcov_hsp_perc {params.coverage} -evalue 1e-6 -max_target_seqs 5 -outfmt "7 qacc sacc qstart qend sstart send length pident qcovhsp qcovs" -out {output}'

rule make_otu_table:
    input:
        blast_res = expand("{dir}/{sample_id}.txt", dir=config["dir_names"]["blast_dir"], sample_id=sample_ids),
        taxonomy = expand("{dir}/{name}/{version}/{file}", dir=config["database"]["base_dir"], name=config["database"]["name"], version=config["database"]["version"], file=config["database"]["tax_file"]) 
    output: expand("{dir}/{file}", dir=config["dir_names"]["table_dir"], file=config["file_names"]["table_results"]["absolute_otu_table"])
    shell: "python tools/my-tools/build_otu_table.py {input.blast_res} {input.taxonomy} {output}"

rule absolute_2_relative:
    input: rules.make_otu_table.output
    output: expand("{dir}/{file}", dir=config["dir_names"]["table_dir"], file=config["file_names"]["table_results"]["relative_otu_table"])
    shell: "python tools/my-tools/absolute_2_relative.py {input} {output}"

rule count:
    input:
        original_count = expand("{dir}/{sample_id}_R1.fq", dir=config["dir_names"]["unzip_dir"], sample_id=sample_ids),
        join_count = expand("{dir}/{sample_id}.assembled.fastq", dir=config["dir_names"]["join_dir"], sample_id=sample_ids),
        filter_count = expand("{dir}/{sample_id}.fq", dir=config["dir_names"]["filter_dir"], sample_id=sample_ids),
        blast_count = rules.make_otu_table.output
    output: expand("{dir}/{file}", dir=config["dir_names"]["table_dir"], file=config["file_names"]["table_results"]["seq_count_table"])
    shell: "python tools/my-tools/count.py {input.original_count} {input.join_count} {input.filter_count} {input.blast_count} {output}"
    
rule clean:
    params: 
        dirs = config["dir_names"].values(),
        mkdir_done = config["file_names"]["mkdir_done"],
        mkblastdb_done = config["file_names"]["mkblastdb_done"],
        database = config["database"]["name"] + "*"
    shell: "rm -rf {params.dirs} {params.mkdir_done} {params.mkblastdb_done} {params.database}"
